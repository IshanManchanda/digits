Have a commanding script that invokes the training script using multiprocessing.

Each training script will manage it's own wandb.

??: GUI will be generated by each training script.
OR: Each will return a neural network object with which the GUI is generated by
	calling script.

Maybe, have a train.py which is invoked by digits.py (normally, same thread.)
digits.py will manage it's own wandb.
digits.py will load_data if called with __main__.

Runner.py (or something else) will call a bunch of digits.py in multiple threads.
